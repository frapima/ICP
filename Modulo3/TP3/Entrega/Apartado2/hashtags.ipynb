{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Francisco Javier Piqueras Martínez\n",
    "\n",
    "# TP3 - Apartado 2 - Infraestructuras Computacionales para el Procesamiento de Datos Masivos\n",
    "## Ejercicio 2\n",
    "\n",
    "Desarrollar un notebook de Jupyter, denominado “hashtags.ipynb”, en el que se utilice como fuente de datos Kafka, y en concreto el topic kafkaTwitter. La duración del batch será de 5 segundos. Se procesarán los tweets que lleguen para extraer los hashtags que contengan (tener en cuenta que todos los hashtags comienzan por el carácter ‘#’). Se irán mostrando, cada vez que se procese el batch (5 segundos) los diez hashtags más utilizados desde el inicio del programa hasta ese momento y el número total de apariciones de cada uno, ordenados de mayor a menor frecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos los imports necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/Users/javierpiquerasmartinez/dev/spark-2.4.4-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME']='/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS']='--master local[*] --packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.4.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.streaming\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la función para, más adelante, devolver los campos que sigan cierto patrón, o null en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def getRegex(word, regex):\n",
    "    match_obj = re.search(regex, word)\n",
    "    \n",
    "    if type(match_obj) is None:\n",
    "        return \"NULL\"\n",
    "    else:\n",
    "        return match_obj.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos el SparkContext y el StreamingContext, con una duración de batch de 5 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master=\"local[*]\", appName=\"Hashtags\")\n",
    "ssc = StreamingContext(sc, batchDuration=5)\n",
    "ssc.checkpoint(\"checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la recepción de datos, creamos un DirectStream que atienda a el evento 'kafkaTwitter' en el servidor localhost:9092."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstream = KafkaUtils.createDirectStream(\n",
    "    ssc, \n",
    "    topics = ['kafkaTwitter'],\n",
    "    kafkaParams = {\n",
    "        'bootstrap.servers' : 'localhost:9092'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente, recogemos todos los tweets y realizamos un filtrado de solamente aquellas palabras que contengan delante el símbolo '#'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = dstream.flatMap(\n",
    "    lambda tweet: (tweet[1].split(\" \"))\n",
    ").filter(\n",
    "    lambda word: (\"#\" in word)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y comprobamos que sigan el patrón '#\\w+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_hashtags = hashtags.map(lambda x: (getRegex(x,'#\\w+')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente, creamos una tupla de (hashtag, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashtags_batch = real_hashtags.map( lambda ht: (ht, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateNum(values, count):\n",
    "    return sum(values) + (count or 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la reducimos aquí para sumar cada aparcición de un mismo hashtag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashtags = num_hashtags_batch.updateStateByKey(updateFunc=updateNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = num_hashtags.transform( \n",
    "    lambda ht_count: (ht_count.sortBy(\n",
    "        lambda pair: ( pair[1]), ascending=False\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, imprimimos el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pprint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2020-01-12 18:10:20\n",
      "-------------------------------------------\n",
      "('#Apple', 6)\n",
      "('#UAM', 3)\n",
      "('#FelizLunes', 3)\n",
      "('#ForoCambio11J', 3)\n",
      "('#UnasPrimariasParaGanar', 3)\n",
      "('#OSX', 3)\n",
      "('#YoHagoHistoria', 2)\n",
      "('#cumPPlimos', 2)\n",
      "('#GobernarParaLaMayoria', 2)\n",
      "('#UniDeVerano', 2)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-01-12 18:10:25\n",
      "-------------------------------------------\n",
      "('#Apple', 6)\n",
      "('#UAM', 3)\n",
      "('#FelizLunes', 3)\n",
      "('#ForoCambio11J', 3)\n",
      "('#UnasPrimariasParaGanar', 3)\n",
      "('#OSX', 3)\n",
      "('#GobernarParaLaMayoria', 3)\n",
      "('#YoHagoHistoria', 2)\n",
      "('#cumPPlimos', 2)\n",
      "('#UniDeVerano', 2)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-01-12 18:10:30\n",
      "-------------------------------------------\n",
      "('#Apple', 6)\n",
      "('#UAM', 3)\n",
      "('#FelizLunes', 3)\n",
      "('#ForoCambio11J', 3)\n",
      "('#UnasPrimariasParaGanar', 3)\n",
      "('#OSX', 3)\n",
      "('#GobernarParaLaMayoria', 3)\n",
      "('#YoHagoHistoria', 2)\n",
      "('#cumPPlimos', 2)\n",
      "('#UniDeVerano', 2)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-01-12 18:10:35\n",
      "-------------------------------------------\n",
      "('#Apple', 7)\n",
      "('#UAM', 3)\n",
      "('#FelizLunes', 3)\n",
      "('#ForoCambio11J', 3)\n",
      "('#UnasPrimariasParaGanar', 3)\n",
      "('#OSX', 3)\n",
      "('#GobernarParaLaMayoria', 3)\n",
      "('#UniDeVerano', 3)\n",
      "('#RdPPodemos', 2)\n",
      "('#ColorPSOE', 2)\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
